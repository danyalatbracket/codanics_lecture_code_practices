{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3456337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1288705.4778516763\n",
      "R2 Score: 0.9189331350419386\n",
      "Mean Absolute Error: 737.1513665933285\n",
      "Mean Absolute Percentage Error: 0.3952933516494362\n",
      "Root Mean Squared Error: 1135.2116445190634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#data pre processing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "#ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load the data\n",
    "df = sns.load_dataset('diamonds')\n",
    "\n",
    "# separate the features X and the target/labels y\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# numeric features\n",
    "numeric_features = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "# categorical features\n",
    "categorical_features = ['cut', 'color', 'clarity']\n",
    "\n",
    "# preprocess the data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# metric to evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred)}\")\n",
    "# root mean squared error\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error(y_test, y_pred))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da60b01",
   "metadata": {},
   "source": [
    "# Interpretation of the model Metrics¶\n",
    "The Metrics indicate the performance of your regression model.\n",
    "\n",
    "Here's a brief interpretation:\n",
    "\n",
    "Mean Squared Error (MSE): 1288813.63 - This value represents the average of the squares of the errors. A lower MSE indicates a better fit, but the value itself is not very interpretable without context.\n",
    "\n",
    "e.g: if the target variable is in the range of 0-100, an MSE of 1288813.63 is high, but if the target variable is in the range of 100000-1000000, then the MSE is low.\n",
    "\n",
    "R2 Score: 0.9189 - This value indicates that approximately 91.89% of the variance in the dependent variable (price) is predictable from the independent variables. An R2 score close to 1 indicates a good fit.\n",
    "\n",
    "e.g: if the R2 score is 0.9189, it means that 91.89% of the variance in the price can be explained by the independent variables in the model.\n",
    "\n",
    "Mean Absolute Error (MAE): 736.91 - This value represents the average absolute difference between the predicted and actual values. Lower values indicate better performance.\n",
    "e.g: if the MAE is 736.91, it means that, on average, the model's predictions are off by $736.91.\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE): 0.3951 - This value represents the average absolute percentage difference between the predicted and actual values. Lower values indicate better performance.\n",
    "\n",
    "e.g: if the MAPE is 0.3951, it means that, on average, the model's predictions are off by 39.51%.\n",
    "\n",
    "Root Mean Squared Error (RMSE): 1135.26 - This value is the square root of the MSE and provides a measure of the average magnitude of the error. Lower values indicate better performance.\n",
    "\n",
    "e.g: if the RMSE is 1135.26, it means that, on average, the model's predictions are off by $1135.26.\n",
    "\n",
    "Overall, the R2 score of 0.9189 suggests that your model explains a significant portion of the variance in the data, which is a good sign. However, the MSE, MAE, and RMSE values are relatively high, indicating that there is still room for improvement in the model's accuracy.\n",
    "\n",
    "Conclusion\n",
    "In this notebook, we created a multi-linear regression model using the sklearn library and saved it to a file. We then loaded the model from the file and used it to make predictions. We also evaluated the model's performance using various metrics such as MSE, R2 score, MAE, MAPE, and RMSE. The results indicate that the model explains a significant portion of the variance in the data but has room for improvement in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e4cc3",
   "metadata": {},
   "source": [
    "# 15 Ways to improve the ML Model's performance?¶\n",
    "\n",
    "Feature Engineering: Create new features that capture additional information from the data.\n",
    "Hyperparameter Tuning: Optimize the model's hyperparameters to improve performance.\n",
    "Regularization: Apply regularization techniques to prevent overfitting.\n",
    "Ensemble Methods: Use ensemble methods such as Random Forest or Gradient Boosting to improve predictive performance.\n",
    "Cross-Validation: Use cross-validation to assess the model's performance more accurately.\n",
    "Feature Selection: Identify and select the most relevant features for the model.\n",
    "Data Preprocessing: Clean and preprocess the data to improve model performance.\n",
    "Model Selection: Experiment with different regression models to find the best fit for the data.\n",
    "Error Analysis: Analyze the model's errors to identify patterns and areas for improvement.\n",
    "Domain Knowledge: Incorporate domain knowledge to improve the model's predictive power.\n",
    "Data Augmentation: Increase the size of the training data through data augmentation techniques.\n",
    "Model Stacking: Combine multiple models to improve predictive performance.\n",
    "Model Interpretation: Interpret the model's predictions to gain insights into the data and improve performance.\n",
    "Model Deployment: Deploy the model in a production environment and monitor its performance over time.\n",
    "Feedback Loop: Incorporate feedback from users and stakeholders to continuously improve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
