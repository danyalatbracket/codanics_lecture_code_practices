{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ecaff2",
   "metadata": {},
   "source": [
    "# **Main Assignment:**\n",
    "\n",
    "## Write the complete code to select the best Regressor and classifier for the given dataset called diamonds `(if you have a high end machine, you can use the whole dataset, else use the sample dataset provided )` or you can use Tips datset for Regression task and Iris dataset for Classification task.\n",
    "\n",
    "## You have to choose all possible models with their best or possible hyperparameters and compare them with each other and select the best model for the given dataset.\n",
    "\n",
    "## Your code should be complete and explained properly. for layman, each and every step of the code should be commented properly.\n",
    "\n",
    "## You code should also save the best model in the pickle file.\n",
    "\n",
    "## You should also write the code to load the pickle file and use it for prediction. in the last snippet of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7843a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using Iris dataset with multiple models\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "# Preprocessing (only numeric features)\n",
    "clf_preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), X.columns)\n",
    "])\n",
    "\n",
    "# Classification models\n",
    "clf_models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=200),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVC': SVC(),\n",
    "    'NaiveBayes': GaussianNB()\n",
    "}\n",
    "\n",
    "best_clf_model = None\n",
    "best_clf_score = float('-inf')\n",
    "best_clf_name = \"\"\n",
    "\n",
    "# Evaluate all classifiers\n",
    "for name, model in clf_models.items():\n",
    "    clf_pipeline = Pipeline([\n",
    "        ('preprocessor', clf_preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    scores = cross_val_score(clf_pipeline, X_train, y_train, scoring='accuracy', cv=5)\n",
    "    mean_score = scores.mean()\n",
    "    print(f\"{name} Accuracy (CV): {mean_score:.4f}\")\n",
    "    if mean_score > best_clf_score:\n",
    "        best_clf_score = mean_score\n",
    "        best_clf_model = clf_pipeline\n",
    "        best_clf_name = name\n",
    "\n",
    "# Train best model\n",
    "best_clf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred = best_clf_model.predict(X_test)\n",
    "print(f\"\\nBest Classification Model: {best_clf_name}\")\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save best classifier model\n",
    "with open('best_iris_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(best_clf_model, f)\n",
    "\n",
    "# # Load and predict\n",
    "# with open('best_iris_classifier.pkl', 'rb') as f:\n",
    "#     loaded_clf_model = pickle.load(f)\n",
    "\n",
    "# # Predict on a few samples\n",
    "# sample_clf_input = X_test.iloc[:5]\n",
    "# sample_clf_pred = loaded_clf_model.predict(sample_clf_input)\n",
    "# sample_clf_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and predict\n",
    "with open(\"best_iris_classifier.pkl\", \"rb\") as f:\n",
    "    loaded_clf_model = pickle.load(f)\n",
    "\n",
    "# Predict on a few samples\n",
    "sample_clf_input = X_test.iloc[:5]\n",
    "sample_clf_pred = loaded_clf_model.predict(sample_clf_input)\n",
    "sample_clf_pred\n",
    "accuracy_score(y_test.iloc[:5], sample_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = sns.load_dataset('Diamonds')\n",
    "data.shape\n",
    "data = data[:1000]\n",
    "data\n",
    "data['clarity'].value_counts()\n",
    "# Label encode categorical variables\n",
    "le = LabelEncoder()\n",
    "data['cut'] = le.fit_transform(data['cut'])\n",
    "data['color'] = le.fit_transform(data['color'])\n",
    "data['clarity'] = le.fit_transform(data['clarity'])\n",
    "data\n",
    "\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using Iris dataset with multiple models\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "data = sns.load_dataset(\"Diamonds\")\n",
    "data.shape\n",
    "data = data[:1000]\n",
    "\n",
    "le = LabelEncoder()\n",
    "data[\"cut\"] = le.fit_transform(data[\"cut\"])\n",
    "data[\"color\"] = le.fit_transform(data[\"color\"])\n",
    "data[\"clarity\"] = le.fit_transform(data[\"clarity\"])\n",
    "\n",
    "\n",
    "X = data.drop(\"price\", axis=1)\n",
    "y = data[\"price\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessing (only numeric features)\n",
    "clf_preprocessor = ColumnTransformer([(\"num\", StandardScaler(), X.columns)])\n",
    "\n",
    "# Classification models\n",
    "clf_models = {\n",
    "    \"LogisticRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(max_depth=5),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"SVC\": SVR(),\n",
    "    \"NaiveBayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "best_clf_model = None\n",
    "best_clf_score = float(\"-inf\")\n",
    "best_clf_name = \"\"\n",
    "\n",
    "# Evaluate all classifiers\n",
    "for name, model in clf_models.items():\n",
    "    clf_pipeline = Pipeline([(\"preprocessor\", clf_preprocessor), (\"classifier\", model)])\n",
    "    scores = cross_val_score(clf_pipeline, X_train, y_train, scoring=\"r2\", cv=5)\n",
    "    mean_score = scores.mean()\n",
    "    print(f\"{name} Accuracy (CV): {mean_score:.4f}\")\n",
    "    if mean_score > best_clf_score:\n",
    "        best_clf_score = mean_score\n",
    "        best_clf_model = clf_pipeline\n",
    "        best_clf_name = name\n",
    "\n",
    "# Train best model\n",
    "best_clf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred = best_clf_model.predict(X_test)\n",
    "print(f\"\\nBest Classification Model: {best_clf_name}\")\n",
    "print(\"Test Accuracy:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Save best classifier model\n",
    "with open(\"best_iris_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_clf_model, f)\n",
    "\n",
    "# # Load and predict\n",
    "# with open('best_iris_classifier.pkl', 'rb') as f:\n",
    "#     loaded_clf_model = pickle.load(f)\n",
    "\n",
    "# # Predict on a few samples\n",
    "# sample_clf_input = X_test.iloc[:5]\n",
    "# sample_clf_pred = loaded_clf_model.predict(sample_clf_input)\n",
    "# sample_clf_pred"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
